# 01. 프로젝트 개요

## 현재 운영 현황

### 문제점
투비네트웍스 글로벌은 현재 판매 채널(네이버 스마트스토어 등)에 등록된 FAQ에 대해 다음과 같은 방식으로 운영하고 있습니다:

1. **수동 응대 프로세스**
   - CS 파트 담당 사원이 모든 문의 내용을 일일이 확인
   - ChatGPT 등 AI 애플리케이션으로 문맥 검수
   - 수동으로 응대 답글 작성

2. **정보 조회 비효율**
   - 제품 문의 시 사내 전산망 또는 QC 담당 사원에게 별도 문의
   - 제품 스펙이나 QC 시트가 체계적으로 관리되지 않음
   - 정보 조회에 많은 시간과 노력 소요

3. **처리량 제한**
   - 하루 평균 10~30건 처리 (월 300~900건)
   - 1건당 평균 2시간 소요
   - CS 사원 업무 과부하

### 비용 및 리소스
- CS 사원 인건비: 월 평균 300만원
- 1건당 처리 비용: 약 10,000원
- 월 처리 비용: 3,000,000원 (인건비) + α (기회비용)

---

## 개선 방향

### 목표
**AI 에이전트가 1차 답변을 자동 생성하고, CS 사원은 검수만 수행하는 시스템 구축**

### 개선 사항

#### 1. 자동 답변 생성
- 일정 시간마다 미응답 질문 수집
- AI 에이전트가 스스로 답변 창출
- 답변 가능 여부 자동 판단 (신뢰도 평가)

#### 2. 효율적 검수 프로세스
- CS 사원은 AI가 생성한 답변 검수만 수행
- 승인/수정/거부 워크플로우
- API를 통해 판매 채널에 자동 등록

#### 3. 지식 체계화
- 제품 스펙 및 QC 시트 데이터베이스화
- RAG(Retrieval-Augmented Generation) 시스템 구축
- 실시간 정보 업데이트 가능

---

## 준비 사항

### ✅ 준비된 것
1. **데이터 수집 인프라**
   - 일정 시간마다 FAQ 목록 API 호출 가능
   - 고객 정보 및 주문 정보 조회 가능
   - 누가 어떤 제품을 구매했는지 추적 가능

2. **기술 스택 선정 완료**
   - 질문 분석: Sentence-BERT + spaCy
   - 벡터 검색: Weaviate
   - 데이터 저장: MongoDB
   - 답변 생성: Claude (검토 중)

### ⚠️ 준비 필요
1. **제품 지식 베이스 구축**
   - 각 제품의 QC 시트 수집 및 정리
   - 제품 스펙 문서 데이터베이스화
   - 호환성 정보, 펌웨어/드라이버 정보 정리

2. **데이터 저장소 설계**
   - MongoDB 스키마 설계
   - Weaviate 클래스 정의
   - 인덱스 전략 수립

---

## 구현 유의사항

### 1. 동적 지식 관리
**문제**: 제품 스펙과 같은 최신 정보는 내용 변동이 잦음

**해결**: RAG 형식으로 유지
- 제품 정보를 벡터화하여 Weaviate에 저장
- MongoDB에 원본 데이터 보관
- 업데이트 시 벡터만 재생성하여 반영

### 2. 답변 유보 시스템
**문제**: 전문 지식이 필요한 질문은 AI가 답변하기 어려움

**해결**: 신뢰도 평가 시스템
- 제품 호환성, 펌웨어, 드라이버 등 전문 용어 감지
- 신뢰도 점수 계산 (0~100점)
- 임계값 이하 시 사람(CS 사원)에게 자동 에스컬레이션

```python
# 신뢰도 평가 예시
if confidence_score >= 70:
    status = "auto_approved"  # 자동 승인 가능
elif confidence_score >= 50:
    status = "review_required"  # 검토 필요
else:
    status = "escalate_to_human"  # 사람 처리 필요
```

### 3. 파인튜닝 가능성
**조건부 실행**:
- 일정 수준의 Q&A가 축적된 경우 (500건 이상)
- CS 사원이 승인한 고품질 답변 데이터 확보
- 모델 성능 개선이 필요하다고 판단될 경우

**진행하지 않는 경우**:
- 데이터가 부족한 경우
- 현재 모델 성능이 충분한 경우
- 비용 대비 효과가 낮은 경우

---

## 확장 가능성

### Phase 1: 반자동 시스템 (현재 목표)
```
[미응답 FAQ] 
  → [AI 답변 생성] 
  → [CS 사원 검수] 
  → [승인/수정/거부] 
  → [판매 채널 등록]
```

### Phase 2: 완전 자동화 (미래)
**조건**:
- AI 답변 품질이 충분히 검증됨
- 신뢰도 평가 알고리즘 정확도 95% 이상
- 경영진 승인

**프로세스**:
```
[미응답 FAQ] 
  → [AI 답변 생성] 
  → [신뢰도 평가]
      ├─ 높음: [자동 등록]
      └─ 낮음: [CS 사원 검수]
```

### Phase 3: 고객 직접 응대
**조건**:
- Phase 2가 안정적으로 운영됨
- 고객 만족도 지표 달성
- 실시간 응답 인프라 구축

**프로세스**:
```
[고객 질문] 
  → [실시간 AI 답변] 
  → [고객에게 즉시 전달]
      (백그라운드에서 CS 모니터링)
```

---

## 기대 효과

### 정량적 효과

| 지표 | 현재 | 목표 | 개선율 |
|------|------|------|--------|
| **평균 응답 시간** | 2시간 | 30분 | 75% ↓ |
| **일일 처리 건수** | 10~30건 | 100~300건 | 10배 ↑ |
| **CS 작업 시간** | 100% | 20% | 80% ↓ |
| **월 처리 비용** | $3,000 | $750 + $75(AI) | 72% ↓ |

### 정성적 효과

1. **고객 만족도 향상**
   - 빠른 응답 시간으로 고객 경험 개선
   - 24시간 응대 가능 (시스템 운영 시)

2. **CS 사원 업무 만족도 향상**
   - 반복적인 단순 작업 감소
   - 복잡하고 의미 있는 업무에 집중
   - 전문성 향상 기회

3. **비즈니스 인사이트**
   - 문의 데이터 분석을 통한 제품 개선
   - 고객 니즈 파악
   - FAQ 트렌드 분석

4. **확장성 확보**
   - 처리량 제한 없이 성장 가능
   - 새로운 제품 추가 시 쉽게 확장
   - 다른 채널로 확대 적용 가능

---

## 위험 요소 및 대응 방안

### 기술적 위험

| 위험 | 영향도 | 대응 방안 |
|------|--------|-----------|
| AI 답변 오류 | 높음 | 신뢰도 평가 + 필수 검수 |
| 시스템 다운타임 | 중간 | 이중화 + 모니터링 |
| 데이터 부족 | 낮음 | 기존 FAQ 활용 + 점진적 개선 |

### 운영 위험

| 위험 | 영향도 | 대응 방안 |
|------|--------|-----------|
| CS 사원 적응 | 중간 | 교육 + 단계적 도입 |
| 고객 불만 | 낮음 | 파일럿 테스트 + 점진적 확대 |
| 비용 초과 | 낮음 | 월별 모니터링 + 예산 통제 |

---

## 다음 단계

1. **Phase 1: 인프라 구축** (1주)
   - Docker 환경 설정
   - Weaviate, MongoDB 설치
   - 개발 환경 구성

2. **Phase 2: 데이터 준비** (1주)
   - 제품 스펙 수집 및 정리
   - 샘플 FAQ 50개 작성
   - 데이터베이스 임포트

3. **Phase 3: AI 코어 개발** (2주)
   - 질문 분석 모듈 구현
   - RAG 파이프라인 구축
   - 신뢰도 평가 시스템 개발

자세한 일정은 [개발 계획](./09_개발_계획.md)을 참조하세요.
