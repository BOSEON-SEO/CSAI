#!/usr/bin/env python3
# backend/scripts/import_data.py
# 2025-10-02 09:00, Claude ì‘ì„±

"""
í†µí•© ë°ì´í„° ì„í¬íŠ¸ ìŠ¤í¬ë¦½íŠ¸

CSV/JSON ë°ì´í„°ë¥¼ MongoDBì— ì„í¬íŠ¸í•˜ëŠ” í†µí•© ìŠ¤í¬ë¦½íŠ¸ì…ë‹ˆë‹¤.
ê¸°ì¡´ mongodb_service.pyì™€ import_products.pyì˜ ê¸°ëŠ¥ì„ í†µí•©í–ˆìŠµë‹ˆë‹¤.

ì£¼ìš” ê¸°ëŠ¥:
1. CSV íŒŒì¼ ì½ê¸° ë° íŒŒì‹±
2. JSON íŒŒì¼ ì½ê¸°
3. MongoDB ì—°ê²° ë° ë°ì´í„° ì‚½ì…
4. ì¤‘ë³µ ë°ì´í„° ì²˜ë¦¬ (upsert)
5. ì§„í–‰ ìƒí™© ë¡œê¹…

ì‚¬ìš©ë²•:
    # ì œí’ˆ ë°ì´í„° ì„í¬íŠ¸
    python import_data.py --type products --source ../data/raw/products_keychron.csv
    
    # FAQ ë°ì´í„° ì„í¬íŠ¸
    python import_data.py --type faqs --source ../data/raw/faq_data_sample.csv
    
    # íŠ¹ì • ë¸Œëœë“œë§Œ ì„í¬íŠ¸
    python import_data.py --type products --source ../data/raw/products_keychron.csv --brand KEYCHRON
"""

import sys
import json
import csv
import argparse
import logging
from pathlib import Path
from typing import List, Dict, Any, Optional
from datetime import datetime
import asyncio

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))
sys.path.insert(0, str(project_root / "backend"))

from motor.motor_asyncio import AsyncIOMotorClient
from pymongo import ASCENDING, IndexModel


# ==================== ë¡œê¹… ì„¤ì • ====================

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(project_root / 'logs' / 'import_data.log', encoding='utf-8')
    ]
)
logger = logging.getLogger(__name__)


# ==================== ë°ì´í„° ë¡œë” ====================

class DataLoader:
    """
    ë°ì´í„° íŒŒì¼ ë¡œë”
    
    CSV, JSON íŒŒì¼ì„ ì½ì–´ì„œ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    
    @staticmethod
    def load_csv(filepath: Path, encoding: str = 'utf-8') -> List[Dict[str, Any]]:
        """
        CSV íŒŒì¼ ë¡œë“œ
        
        Args:
            filepath: CSV íŒŒì¼ ê²½ë¡œ
            encoding: íŒŒì¼ ì¸ì½”ë”©
            
        Returns:
            ë°ì´í„° ë¦¬ìŠ¤íŠ¸
        """
        logger.info(f"ğŸ“„ CSV íŒŒì¼ ë¡œë“œ ì¤‘: {filepath}")
        
        data = []
        with open(filepath, 'r', encoding=encoding) as f:
            reader = csv.DictReader(f)
            for row in reader:
                # ë¹ˆ ë¬¸ìì—´ì„ Noneìœ¼ë¡œ ë³€í™˜
                cleaned_row = {
                    k: (v if v.strip() else None) if isinstance(v, str) else v
                    for k, v in row.items()
                }
                data.append(cleaned_row)
        
        logger.info(f"âœ… {len(data)}ê°œ í–‰ ë¡œë“œ ì™„ë£Œ")
        return data
    
    @staticmethod
    def load_json(filepath: Path, encoding: str = 'utf-8') -> List[Dict[str, Any]]:
        """
        JSON íŒŒì¼ ë¡œë“œ
        
        Args:
            filepath: JSON íŒŒì¼ ê²½ë¡œ
            encoding: íŒŒì¼ ì¸ì½”ë”©
            
        Returns:
            ë°ì´í„° ë¦¬ìŠ¤íŠ¸ ë˜ëŠ” ë‹¨ì¼ ë°ì´í„°ë¥¼ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¼ ê²ƒ
        """
        logger.info(f"ğŸ“„ JSON íŒŒì¼ ë¡œë“œ ì¤‘: {filepath}")
        
        with open(filepath, 'r', encoding=encoding) as f:
            data = json.load(f)
        
        # ë‹¨ì¼ ê°ì²´ë©´ ë¦¬ìŠ¤íŠ¸ë¡œ ê°ì‹¸ê¸°
        if isinstance(data, dict):
            data = [data]
        
        logger.info(f"âœ… {len(data)}ê°œ í•­ëª© ë¡œë“œ ì™„ë£Œ")
        return data


# ==================== ë°ì´í„° ë³€í™˜ê¸° ====================

class DataTransformer:
    """
    ë°ì´í„° ë³€í™˜ê¸°
    
    ì›ë³¸ ë°ì´í„°ë¥¼ MongoDB ìŠ¤í‚¤ë§ˆì— ë§ê²Œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    
    @staticmethod
    def transform_product(raw_data: Dict[str, Any], brand_channel: str) -> Dict[str, Any]:
        """
        ì œí’ˆ ë°ì´í„° ë³€í™˜
        
        Args:
            raw_data: ì›ë³¸ CSV/JSON ë°ì´í„°
            brand_channel: ë¸Œëœë“œ ì±„ë„ëª…
            
        Returns:
            ë³€í™˜ëœ ì œí’ˆ ë°ì´í„°
        """
        # í•„ìˆ˜ í•„ë“œ
        product = {
            'product_id': str(raw_data.get('id', '')),
            'brand_channel': brand_channel.upper(),
            'product_name': raw_data.get('product_name', ''),
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        }
        
        # ì„ íƒ í•„ë“œ (ìˆìœ¼ë©´ ì¶”ê°€)
        optional_fields = [
            'product_name_synonyms', 'price', 'discontinued', 'release_date',
            'key_binding', 'tags', 'features', 'keyboard_layout', 'keyboard_type',
            'switch_options', 'multi_media_key_count', 'main_frame_material',
            'key_cap_profile', 'stabilizer', 'reinforcing_plate', 'n_key_rollover',
            'plug_and_play', 'polling_rate', 'support_platforms', 'battery_capacity',
            'bluetooth_runtime', 'backlight_pattern', 'connection_method',
            'supports_2_4ghz', 'dynamic_keystroke', 'hot_swap_socket', 'rapid_trigger',
            'size', 'height_including_key_cap', 'height_not_including_key_cap',
            'package_contents', 'warranty_period', 'weight', 'color', 'color_details'
        ]
        
        for field in optional_fields:
            value = raw_data.get(field)
            if value is not None:
                # Boolean ë³€í™˜
                if field == 'discontinued':
                    product[field] = str(value).lower() in ('true', '1', 'yes', 't')
                # íƒœê·¸ëŠ” ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                elif field == 'tags' and isinstance(value, str):
                    product[field] = [tag.strip() for tag in value.split(',') if tag.strip()]
                else:
                    product[field] = value
        
        return product
    
    @staticmethod
    def transform_faq(raw_data: Dict[str, Any]) -> Dict[str, Any]:
        """
        FAQ ë°ì´í„° ë³€í™˜
        
        Args:
            raw_data: ì›ë³¸ CSV/JSON ë°ì´í„°
            
        Returns:
            ë³€í™˜ëœ FAQ ë°ì´í„°
        """
        # ë‚ ì§œ íŒŒì‹±
        try:
            reg_date = datetime.strptime(
                raw_data.get('inquiry_registration_date_time', ''),
                '%Y-%m-%d %H:%M:%S'
            )
        except:
            reg_date = datetime.now()
        
        faq = {
            'inquiry_no': int(raw_data.get('inquiry_no', 0)),
            'brand_channel': raw_data.get('brand_channel', '').upper(),
            'internal_product_code': raw_data.get('internal_product_code', ''),
            'inquiry_category': raw_data.get('inquiry_category', ''),
            'title': raw_data.get('title', ''),
            'inquiry_content': raw_data.get('inquiry_content', ''),
            'inquiry_registration_date_time': reg_date,
            'customer_id': raw_data.get('customer_id', ''),
            'customer_name': raw_data.get('customer_name', ''),
            'order_id': raw_data.get('order_id', ''),
            'naver_product_no': raw_data.get('naver_product_no', ''),
            'product_name': raw_data.get('product_name', ''),
            'product_order_option': raw_data.get('product_order_option', ''),
            'answer_content': raw_data.get('answer_content', ''),
            'answered': raw_data.get('answered', 'false').lower() in ('true', '1', 'yes', 't'),
            'ai_answer_generated': raw_data.get('ai_answer_generated', 'false').lower() in ('true', '1', 'yes', 't'),
            'cs_reviewed': raw_data.get('cs_reviewed', 'false').lower() in ('true', '1', 'yes', 't'),
            'processing_status': raw_data.get('processing_status', 'pending'),
            'created_at': datetime.now(),
            'updated_at': datetime.now()
        }
        
        return faq


# ==================== MongoDB ì„í¬í„° ====================

class MongoDBImporter:
    """
    MongoDB ë°ì´í„° ì„í¬í„°
    
    ë°ì´í„°ë¥¼ MongoDBì— ì‚½ì…í•˜ê³  ê´€ë¦¬í•©ë‹ˆë‹¤.
    """
    
    def __init__(self, connection_string: str, database_name: str):
        """
        ì´ˆê¸°í™”
        
        Args:
            connection_string: MongoDB ì—°ê²° ë¬¸ìì—´
            database_name: ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„
        """
        self.connection_string = connection_string
        self.database_name = database_name
        self.client: Optional[AsyncIOMotorClient] = None
        self.db = None
    
    async def connect(self):
        """MongoDB ì—°ê²°"""
        logger.info(f"ğŸ”Œ MongoDB ì—°ê²° ì¤‘: {self.database_name}")
        
        try:
            self.client = AsyncIOMotorClient(self.connection_string)
            self.db = self.client[self.database_name]
            
            # ì—°ê²° í…ŒìŠ¤íŠ¸
            await self.client.admin.command('ping')
            
            logger.info("âœ… MongoDB ì—°ê²° ì„±ê³µ!")
            
        except Exception as e:
            logger.error(f"âŒ MongoDB ì—°ê²° ì‹¤íŒ¨: {e}")
            raise
    
    async def disconnect(self):
        """MongoDB ì—°ê²° ì¢…ë£Œ"""
        if self.client:
            self.client.close()
            logger.info("ğŸ”Œ MongoDB ì—°ê²° ì¢…ë£Œ")
    
    async def ensure_indexes(self, collection_name: str):
        """
        ì¸ë±ìŠ¤ ìƒì„±
        
        Args:
            collection_name: ì»¬ë ‰ì…˜ ì´ë¦„
        """
        logger.info(f"ğŸ”§ {collection_name} ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
        
        if collection_name == 'products':
            indexes = [
                IndexModel([("product_id", ASCENDING)], unique=True),
                IndexModel([("brand_channel", ASCENDING)]),
                IndexModel([("product_name", ASCENDING)]),
            ]
            await self.db.products.create_indexes(indexes)
        
        elif collection_name == 'faqs':
            indexes = [
                IndexModel([("inquiry_no", ASCENDING)], unique=True),
                IndexModel([("brand_channel", ASCENDING)]),
                IndexModel([("inquiry_category", ASCENDING)]),
                IndexModel([("answered", ASCENDING)]),
                IndexModel([("processing_status", ASCENDING)]),
            ]
            await self.db.faqs.create_indexes(indexes)
        
        logger.info(f"âœ… {collection_name} ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    
    async def import_products(
        self,
        products: List[Dict[str, Any]],
        brand_filter: Optional[str] = None
    ) -> Dict[str, int]:
        """
        ì œí’ˆ ë°ì´í„° ì„í¬íŠ¸
        
        Args:
            products: ì œí’ˆ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            brand_filter: ë¸Œëœë“œ í•„í„° (ì„ íƒ)
            
        Returns:
            {'inserted': int, 'updated': int, 'failed': int}
        """
        logger.info(f"ğŸ“¦ ì œí’ˆ ë°ì´í„° ì„í¬íŠ¸ ì‹œì‘: {len(products)}ê°œ")
        
        # ì¸ë±ìŠ¤ ìƒì„±
        await self.ensure_indexes('products')
        
        inserted = 0
        updated = 0
        failed = 0
        
        for product in products:
            # ë¸Œëœë“œ í•„í„°ë§
            if brand_filter and product.get('brand_channel') != brand_filter.upper():
                continue
            
            try:
                result = await self.db.products.update_one(
                    {'product_id': product['product_id']},
                    {'$set': product},
                    upsert=True
                )
                
                if result.upserted_id:
                    inserted += 1
                    logger.debug(f"  â• ìƒˆ ì œí’ˆ: {product['product_name']}")
                elif result.modified_count > 0:
                    updated += 1
                    logger.debug(f"  ğŸ”„ ì—…ë°ì´íŠ¸: {product['product_name']}")
                
            except Exception as e:
                failed += 1
                logger.error(f"  âŒ ì‹¤íŒ¨ ({product.get('product_id')}): {e}")
        
        logger.info(f"âœ… ì œí’ˆ ì„í¬íŠ¸ ì™„ë£Œ: ì¶”ê°€ {inserted}, ì—…ë°ì´íŠ¸ {updated}, ì‹¤íŒ¨ {failed}")
        
        return {
            'inserted': inserted,
            'updated': updated,
            'failed': failed
        }
    
    async def import_faqs(
        self,
        faqs: List[Dict[str, Any]],
        brand_filter: Optional[str] = None
    ) -> Dict[str, int]:
        """
        FAQ ë°ì´í„° ì„í¬íŠ¸
        
        Args:
            faqs: FAQ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
            brand_filter: ë¸Œëœë“œ í•„í„° (ì„ íƒ)
            
        Returns:
            {'inserted': int, 'updated': int, 'failed': int}
        """
        logger.info(f"ğŸ’¬ FAQ ë°ì´í„° ì„í¬íŠ¸ ì‹œì‘: {len(faqs)}ê°œ")
        
        # ì¸ë±ìŠ¤ ìƒì„±
        await self.ensure_indexes('faqs')
        
        inserted = 0
        updated = 0
        failed = 0
        
        for faq in faqs:
            # ë¸Œëœë“œ í•„í„°ë§
            if brand_filter and faq.get('brand_channel') != brand_filter.upper():
                continue
            
            try:
                result = await self.db.faqs.update_one(
                    {'inquiry_no': faq['inquiry_no']},
                    {'$set': faq},
                    upsert=True
                )
                
                if result.upserted_id:
                    inserted += 1
                    logger.debug(f"  â• ìƒˆ FAQ: {faq['inquiry_no']}")
                elif result.modified_count > 0:
                    updated += 1
                    logger.debug(f"  ğŸ”„ ì—…ë°ì´íŠ¸: {faq['inquiry_no']}")
                
            except Exception as e:
                failed += 1
                logger.error(f"  âŒ ì‹¤íŒ¨ ({faq.get('inquiry_no')}): {e}")
        
        logger.info(f"âœ… FAQ ì„í¬íŠ¸ ì™„ë£Œ: ì¶”ê°€ {inserted}, ì—…ë°ì´íŠ¸ {updated}, ì‹¤íŒ¨ {failed}")
        
        return {
            'inserted': inserted,
            'updated': updated,
            'failed': failed
        }


# ==================== ë©”ì¸ í•¨ìˆ˜ ====================

async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    
    # ì¸ì íŒŒì‹±
    parser = argparse.ArgumentParser(
        description='CSV/JSON ë°ì´í„°ë¥¼ MongoDBì— ì„í¬íŠ¸',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ì‚¬ìš© ì˜ˆì‹œ:
  # ì œí’ˆ ë°ì´í„° ì„í¬íŠ¸
  python import_data.py --type products --source ../data/raw/products_keychron.csv --brand KEYCHRON
  
  # FAQ ë°ì´í„° ì„í¬íŠ¸
  python import_data.py --type faqs --source ../data/raw/faq_data_sample.csv
  
  # JSON íŒŒì¼ ì„í¬íŠ¸
  python import_data.py --type products --source ../data/products/keychron_products.json
        """
    )
    
    parser.add_argument(
        '--type',
        required=True,
        choices=['products', 'faqs'],
        help='ì„í¬íŠ¸í•  ë°ì´í„° íƒ€ì…'
    )
    
    parser.add_argument(
        '--source',
        required=True,
        help='ì†ŒìŠ¤ íŒŒì¼ ê²½ë¡œ (CSV ë˜ëŠ” JSON)'
    )
    
    parser.add_argument(
        '--brand',
        default='KEYCHRON',
        help='ë¸Œëœë“œ ì±„ë„ëª… (ê¸°ë³¸ê°’: KEYCHRON)'
    )
    
    parser.add_argument(
        '--mongodb-url',
        default='mongodb://csai_user:csai_password_2025@localhost:27017/csai',
        help='MongoDB ì—°ê²° ë¬¸ìì—´'
    )
    
    parser.add_argument(
        '--database',
        default='csai',
        help='ë°ì´í„°ë² ì´ìŠ¤ ì´ë¦„'
    )
    
    parser.add_argument(
        '--filter-brand',
        help='íŠ¹ì • ë¸Œëœë“œë§Œ ì„í¬íŠ¸ (ì„ íƒ)'
    )
    
    args = parser.parse_args()
    
    # íŒŒì¼ ê²½ë¡œ í™•ì¸
    source_path = Path(args.source)
    if not source_path.exists():
        logger.error(f"âŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {source_path}")
        sys.exit(1)
    
    # ë°ì´í„° ë¡œë“œ
    loader = DataLoader()
    
    if source_path.suffix == '.csv':
        raw_data = loader.load_csv(source_path)
    elif source_path.suffix == '.json':
        raw_data = loader.load_json(source_path)
    else:
        logger.error(f"âŒ ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹: {source_path.suffix}")
        sys.exit(1)
    
    if not raw_data:
        logger.error("âŒ ë°ì´í„°ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        sys.exit(1)
    
    # ë°ì´í„° ë³€í™˜
    transformer = DataTransformer()
    
    if args.type == 'products':
        transformed_data = [
            transformer.transform_product(item, args.brand)
            for item in raw_data
        ]
    else:  # faqs
        transformed_data = [
            transformer.transform_faq(item)
            for item in raw_data
        ]
    
    logger.info(f"ğŸ”„ {len(transformed_data)}ê°œ ë°ì´í„° ë³€í™˜ ì™„ë£Œ")
    
    # MongoDB ì„í¬íŠ¸
    importer = MongoDBImporter(args.mongodb_url, args.database)
    
    try:
        await importer.connect()
        
        if args.type == 'products':
            result = await importer.import_products(
                transformed_data,
                brand_filter=args.filter_brand
            )
        else:  # faqs
            result = await importer.import_faqs(
                transformed_data,
                brand_filter=args.filter_brand
            )
        
        # ê²°ê³¼ ì¶œë ¥
        logger.info("=" * 60)
        logger.info("ğŸ“Š ì„í¬íŠ¸ ê²°ê³¼ ìš”ì•½")
        logger.info("=" * 60)
        logger.info(f"  â• ì¶”ê°€ë¨:   {result['inserted']:>5}ê°œ")
        logger.info(f"  ğŸ”„ ì—…ë°ì´íŠ¸: {result['updated']:>5}ê°œ")
        logger.info(f"  âŒ ì‹¤íŒ¨:     {result['failed']:>5}ê°œ")
        logger.info("=" * 60)
        
        if result['failed'] > 0:
            sys.exit(1)
        
    except Exception as e:
        logger.error(f"âŒ ì„í¬íŠ¸ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
    
    finally:
        await importer.disconnect()
    
    logger.info("âœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")


if __name__ == "__main__":
    asyncio.run(main())
