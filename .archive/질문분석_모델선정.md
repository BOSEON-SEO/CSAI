# 질문 분석용 경량 모델 선정 (계속)

```python
                acy_result, sbert_result
            )
        }
    
    def _spacy_analyze(self, question):
        doc = self.nlp(question)
        
        # 명사 추출
        keywords = [
            token.text for token in doc 
            if token.pos_ in ["NOUN", "PROPN"]
        ]
        
        # 제품 코드 추출
        import re
        product_codes = re.findall(
            r'[A-Z]+-[A-Z0-9]+-\d+|[a-zA-Z]+\s?\d+',
            question
        )
        
        # 기술 용어 카운트
        tech_count = sum(
            1 for term in self.tech_keywords 
            if term in question
        )
        
        return {
            "keywords": keywords,
            "product_codes": product_codes,
            "tech_terms_count": tech_count
        }
    
    def _sbert_analyze(self, question):
        # 질문 임베딩
        q_emb = self.embedder.encode(question)
        
        # 카테고리 임베딩
        c_embs = self.embedder.encode(
            list(self.categories.values())
        )
        
        # 유사도 계산
        sims = util.cos_sim(q_emb, c_embs)[0]
        
        best_idx = sims.argmax()
        category = list(self.categories.keys())[best_idx]
        confidence = sims[best_idx].item()
        
        return {
            "category": category,
            "confidence": confidence
        }
    
    def _judge_complexity(self, spacy_result, sbert_result):
        tech_count = spacy_result["tech_terms_count"]
        confidence = sbert_result["confidence"]
        
        if tech_count >= 3 or confidence < 0.6:
            return "complex"
        elif tech_count >= 1:
            return "medium"
        else:
            return "simple"

# 사용 예시
async def main():
    analyzer = QuestionAnalyzer()
    
    # 실제 질문 테스트
    questions = [
        "KB-TKL-001 펌웨어 v2.3에서 블루투스 중복 입력 문제",
        "화이트 구매시 빨간색 키 여분이 구성품일까요?",
        "로지텍 rs50 호환되겠죠?"
    ]
    
    for q in questions:
        result = await analyzer.analyze(q)
        print(f"\n질문: {q}")
        print(f"결과: {result}")

asyncio.run(main())
```

**출력 예시**:
```
질문: KB-TKL-001 펌웨어 v2.3에서 블루투스 중복 입력 문제
결과: {
    'keywords': ['KB-TKL-001', '펌웨어', 'v2.3', '블루투스', '중복', '입력', '문제'],
    'product_codes': ['KB-TKL-001'],
    'tech_terms_count': 3,
    'category': '기술지원',
    'confidence': 0.85,
    'complexity': 'complex'
}

질문: 화이트 구매시 빨간색 키 여분이 구성품일까요?
결과: {
    'keywords': ['화이트', '구매', '빨간색', '키', '여분', '구성품'],
    'product_codes': [],
    'tech_terms_count': 0,
    'category': '제품문의',
    'confidence': 0.92,
    'complexity': 'simple'
}
```

---

## 메모리 사용량 (RTX 3050, 64GB RAM)

```
spaCy (ko_core_news_lg):        ~600MB
Sentence-BERT:                   ~500MB
FastAPI 서버:                    ~200MB
Weaviate (로컬):                 ~800MB
MongoDB (로컬):                  ~400MB
─────────────────────────────────────────
총 메모리 사용:                   ~2.5GB

64GB RAM 중:                     3.9% 사용
남은 메모리:                      ~61.5GB

결론: 메모리는 전혀 문제없음!
```

---

## GPU 활용 (RTX 3050)

```python
# Sentence-BERT GPU 사용
embedder = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')
embedder.to('cuda')  # RTX 3050으로 이동

# 성능 비교
CPU 추론: 30-50ms
GPU 추론: 5-10ms (6배 빠름!)

# 배치 처리 시
CPU: 10개 질문 = 300-500ms
GPU: 10개 질문 = 80ms (5배 빠름!)
```

---

## 최종 추천 구성

### 🥇 1순위: Sentence-BERT + spaCy

**구성**:
```
[질문 입력]
    ↓
┌─────────────────┐  ┌─────────────────┐
│ spaCy           │  │ Sentence-BERT   │
│ (CPU, 10ms)     │  │ (GPU, 5-10ms)   │
│                 │  │                 │
│ 키워드 추출     │  │ 카테고리 분류   │
│ 제품코드 추출   │  │ 신뢰도 계산     │
│ 기술용어 카운트 │  │ 임베딩 생성     │
└─────────────────┘  └─────────────────┘
         │                    │
         └────────┬───────────┘
                  ↓
         [결과 통합: 15-20ms]
                  ↓
         {
           keywords: [...],
           category: "기술지원",
           confidence: 0.85,
           complexity: "complex",
           requires_human: true
         }
```

**이유**:
1. ✅ **속도**: 15-20ms (매우 빠름)
2. ✅ **정확도**: 의미 이해 + 키워드 추출
3. ✅ **비용**: $0/월
4. ✅ **GPU 활용**: RTX 3050 최적화
5. ✅ **메모리**: 1.1GB (충분)
6. ✅ **파인튜닝**: 둘 다 가능
7. ✅ **확장성**: 멀티모달 가능
8. ✅ **개발 난이도**: 낮음

---

## 실제 프로젝트 적용 예시

### 전체 워크플로우 (타이밍)
```
[고객 질문 입력]
    ↓
[1. 질문 분석 - 15ms]
   spaCy + Sentence-BERT
    ↓
[2. 고객 정보 조회 - 10ms]
   MongoDB
    ↓
[3. 유사 FAQ 검색 - 30ms]
   Weaviate
    ↓
[4. 제품 스펙 조회 - 10ms]
   MongoDB
    ↓
[5. 신뢰도 평가 - 5ms]
   Python 로직
    ↓
[6. Claude 답변 생성 - 2000-3000ms]
   Anthropic API
    ↓
[7. 결과 저장 - 10ms]
   MongoDB
    ↓
[총 처리 시간: ~2100ms]
```

**병목 지점**: Claude API (95% 시간 소요)
**최적화 가능**: 질문 분석~신뢰도 평가 (100ms, 5%)

---

## 개발 환경 설정

### Windows (개발용)
```bash
# Python 가상환경
python -m venv venv
venv\Scripts\activate

# 필수 라이브러리
pip install sentence-transformers spacy torch fastapi
python -m spacy download ko_core_news_lg

# GPU 확인
python -c "import torch; print(torch.cuda.is_available())"
# True면 RTX 3050 인식됨
```

### Linux (배포용)
```bash
# Docker Compose로 전체 스택 실행
docker-compose up -d

# 구성
services:
  - question-analyzer (FastAPI + 경량 모델)
  - weaviate (Vector DB)
  - mongodb (NoSQL)
  - frontend (Next.js)
```

---

## 비용 정리 (월 300~900건)

| 항목 | 비용 |
|------|------|
| Sentence-BERT | $0 |
| spaCy | $0 |
| Weaviate (셀프호스팅) | $0 |
| MongoDB (셀프호스팅) | $0 |
| Claude API (900건) | $45 |
| **총 비용** | **$45/월** |

서버 비용 (별도):
- AWS EC2 t3.medium: ~$30/월
- 또는 자체 서버: $0

**결론**: 대부분의 비용은 Claude API, 경량 모델은 무료!

---

## 파인튜닝 계획

### Sentence-BERT 파인튜닝 (6개월 후)

**데이터 수집**:
- 승인된 답변 500개 이상 축적
- 카테고리별 100개 이상

**학습 방법**:
```python
from sentence_transformers import SentenceTransformer, InputExample, losses

# 학습 데이터
train_examples = [
    InputExample(texts=['블루투스 연결 방법', '기술지원'], label=1.0),
    InputExample(texts=['입고 예정일', '배송'], label=1.0),
    # ... 500개
]

model = SentenceTransformer('paraphrase-multilingual-MiniLM-L12-v2')

# 파인튜닝
model.fit(
    train_objectives=[(train_dataloader, train_loss)],
    epochs=5,
    warmup_steps=100
)

model.save('./models/cs-classifier-v1')
```

**기대 효과**:
- 카테고리 정확도: 85% → 95%
- 신뢰도 점수 개선
- 도메인 특화 용어 이해 향상

---

## 결론

### 왜 Sentence-BERT + spaCy인가?

**Sentence-BERT 단독으로는**:
- ✅ 의미 이해 (카테고리 분류)
- ❌ 키워드 추출 불가
- ❌ 제품 코드 인식 불가

**spaCy 단독으로는**:
- ✅ 키워드 추출
- ✅ 제품 코드 추출
- ❌ 의미 이해 부족

**둘을 함께 사용하면** ✨:
- ✅ 의미 이해 (Sentence-BERT)
- ✅ 키워드 추출 (spaCy)
- ✅ 제품 코드 추출 (spaCy)
- ✅ 복잡도 판단 (spaCy 기술 용어 카운트)
- ✅ 빠른 속도 (병렬 처리 15-20ms)
- ✅ 낮은 비용 ($0)
- ✅ 높은 정확도 (상호 보완)

---

## 다음 단계

1. **개발 환경 설정** (1일)
   - Python, spaCy, Sentence-BERT 설치
   - RTX 3050 GPU 설정 확인

2. **프로토타입 개발** (3일)
   - QuestionAnalyzer 클래스 구현
   - 실제 질문 5개로 테스트
   - 성능 측정

3. **FastAPI 통합** (2일)
   - API 엔드포인트 생성
   - Weaviate, MongoDB 연동

4. **프로덕션 배포** (3일)
   - Docker 컨테이너화
   - Linux 서버 배포
   - 모니터링 설정

**총 소요 시간**: 약 2주

---

이 문서는 프로젝트의 **질문 분석 모듈** 기술 스택 선정 근거를 담고 있습니다.
